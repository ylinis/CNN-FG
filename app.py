# app.py

import streamlit as st
import pandas as pd
import requests
from datetime import datetime, date

@st.cache_data
def gauti_ir_apdoroti_duomenis(pradzios_data: date, pabaigos_data: date):
    """
    Gauna ir apdoroja CNN Fear and Greed indekso duomenis.
    GrÄ…Å¾ina pandas DataFrame arba None, jei Ä¯vyko klaida.
    """
    try:
        # <<< --- PAKEITIMAS YRA ÄŒIA --- >>>
        # UÅ¾uot nurodÄ™ pabaigos datÄ…, kreipiamÄ—s Ä¯ bendrÄ… adresÄ…,
        # tikÄ—damiesi gauti visus istorinius duomenis.
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        # <<< --- PAKEITIMO PABAIGA --- >>>
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        r = requests.get(url, headers=headers, timeout=15)
        r.raise_for_status()
        
        duomenys = r.json()
        
        # Tolimesnis kodas lieka visiÅ¡kai toks pat
        df = pd.DataFrame(duomenys['fear_and_greed_historical']['data'])
        df.rename(columns={'x': 'timestamp', 'y': 'reiksme', 'rating': 'ivertinimas'}, inplace=True)
        df['data'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True).dt.date
        df.set_index(pd.to_datetime(df['data']), inplace=True)
        
        # Filtruojame visÄ… gautÄ… duomenÅ³ rinkinÄ¯ pagal vartotojo pasirinktas datas
        filtruotas_df = df.loc[pradzios_data.strftime('%Y-%m-%d'):pabaigos_data.strftime('%Y-%m-%d')]
        
        if filtruotas_df.empty:
            return pd.DataFrame()

        galutinis_df = filtruotas_df[['data', 'reiksme', 'ivertinimas']].sort_index(ascending=False).copy()
        return galutinis_df

    except requests.exceptions.HTTPError as e:
        st.error(f"Serveris atmetÄ— uÅ¾klausÄ…. Klaidos kodas: {e.response.status_code}. Gali bÅ«ti, kad CNN pakeitÄ— prieigÄ… arba laikinai blokuoja uÅ¾klausas.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"Tinklo klaida: Nepavyko gauti duomenÅ³ iÅ¡ CNN. Pabandykite vÄ—liau. Klaida: {e}")
        return None
    except Exception as e:
        st.error(f"Ä®vyko nenumatyta klaida apdorojant duomenis. Klaida: {e}")
        return None

# --- Streamlit Vartotojo SÄ…saja (lieka nepakitusi) ---

st.set_page_config(page_title="Fear & Greed Index Scraper", layout="centered")

st.title("ğŸ“Š CNN Fear & Greed Index Scraper")
st.markdown("Pasirinkite norimÄ… datÅ³ intervalÄ… ir atsisiÅ³skite istorinius duomenis `.csv` formatu.")

st.header("1. Pasirinkite datas")
col1, col2 = st.columns(2)

with col1:
    pradzios_data = st.date_input("PradÅ¾ios data", date(2020, 1, 1)) # PakeiÄiau numatytÄ…jÄ… datÄ…

with col2:
    pabaigos_data = st.date_input("Pabaigos data", datetime.now())

st.header("2. Generuokite failÄ…")

if st.button("Gauti duomenis ir paruoÅ¡ti atsisiuntimui"):
    if pradzios_data > pabaigos_data:
        st.error("Klaida: PradÅ¾ios data negali bÅ«ti vÄ—lesnÄ— uÅ¾ pabaigos datÄ….")
    else:
        with st.spinner('SiunÄiama uÅ¾klausa ir apdorojami duomenys...'):
            df = gauti_ir_apdoroti_duomenis(pradzios_data, pabaigos_data)

        if df is not None:
            if not df.empty:
                st.success(f"âœ… Duomenys sÄ—kmingai gauti! IÅ¡ viso eiluÄiÅ³: {len(df)}")
                st.header("3. PerÅ¾iÅ«ra ir atsisiuntimas")
                st.dataframe(df.head())
                
                csv_duomenys = df.to_csv(index=False).encode('utf-8')
                failo_pavadinimas = f"fear_greed_index_{pradzios_data}_{pabaigos_data}.csv"
                
                st.download_button(
                   label="AtsisiÅ³sti CSV failÄ…",
                   data=csv_duomenys,
                   file_name=failo_pavadinimas,
                   mime='text/csv',
                )
            else:
                st.warning("Pasirinktame datÅ³ intervale duomenÅ³ nerasta.")
